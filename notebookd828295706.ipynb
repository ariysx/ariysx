{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7749502,"sourceType":"datasetVersion","datasetId":4530568},{"sourceId":12178,"sourceType":"modelInstanceVersion","modelInstanceId":9882}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:17:52.476939Z","iopub.execute_input":"2024-03-03T17:17:52.477242Z","iopub.status.idle":"2024-03-03T17:17:53.575016Z","shell.execute_reply.started":"2024-03-03T17:17:52.477216Z","shell.execute_reply":"2024-03-03T17:17:53.573955Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Sun Mar  3 17:17:53 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n| N/A   78C    P0              35W /  70W |      0MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n|   1  Tesla T4                       Off | 00000000:00:05.0 Off |                    0 |\n| N/A   64C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|  No running processes found                                                           |\n+---------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"# import tensorflow as tf\n\n# # Define tand get the number os devices. \n# strategy = tf.distribute.MirroredStrategy()\n# print('DEVICES AVAILABLE: {}'.format(strategy.num_replicas_in_sync))","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:17:53.580595Z","iopub.execute_input":"2024-03-03T17:17:53.580986Z","iopub.status.idle":"2024-03-03T17:17:53.585978Z","shell.execute_reply.started":"2024-03-03T17:17:53.580945Z","shell.execute_reply":"2024-03-03T17:17:53.584920Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import keras","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:17:53.587440Z","iopub.execute_input":"2024-03-03T17:17:53.588070Z","iopub.status.idle":"2024-03-03T17:17:57.427691Z","shell.execute_reply.started":"2024-03-03T17:17:53.588034Z","shell.execute_reply":"2024-03-03T17:17:57.426781Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-03-03 17:17:53.968434: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-03 17:17:53.968492: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-03 17:17:53.970141: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ntrain_generator = ImageDataGenerator(\n    preprocessing_function=keras.applications.xception.preprocess_input,\n    rotation_range=30,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n)\n\nval_generator = ImageDataGenerator(\n    preprocessing_function=keras.applications.xception.preprocess_input,\n)\n\ntest_generator = ImageDataGenerator(\n    preprocessing_function=keras.applications.xception.preprocess_input\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:17:57.431290Z","iopub.execute_input":"2024-03-03T17:17:57.432035Z","iopub.status.idle":"2024-03-03T17:17:57.438111Z","shell.execute_reply.started":"2024-03-03T17:17:57.432006Z","shell.execute_reply":"2024-03-03T17:17:57.436965Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"target_size = (142, 142)\nbatch_size = 32\n# batch_size = 32 * strategy.num_replicas_in_sync\n\ntrain_images = train_generator.flow_from_directory(\n    \"/kaggle/input/refinedsplit/train\",\n    target_size=target_size,\n    batch_size=batch_size,\n    class_mode=\"categorical\",\n    shuffle=True,\n    color_mode=\"rgb\",\n    seed=42\n)\n\nval_images = val_generator.flow_from_directory(\n    \"/kaggle/input/refinedsplit/validation\",\n    target_size=target_size,\n    batch_size=batch_size,\n    class_mode=\"categorical\",\n    shuffle=True,\n    color_mode=\"rgb\",\n    seed=42\n)\n\ntest_images = test_generator.flow_from_directory(\n    \"/kaggle/input/refinedsplit/test\",\n    target_size=target_size,\n    batch_size=batch_size,\n    class_mode=\"categorical\",\n    shuffle=False,\n    color_mode=\"rgb\",\n    seed=42\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:17:57.439420Z","iopub.execute_input":"2024-03-03T17:17:57.439706Z","iopub.status.idle":"2024-03-03T17:17:58.556981Z","shell.execute_reply.started":"2024-03-03T17:17:57.439681Z","shell.execute_reply":"2024-03-03T17:17:58.556193Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Found 14700 images belonging to 21 classes.\nFound 3150 images belonging to 21 classes.\nFound 3150 images belonging to 21 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.applications import Xception\nfrom keras.models import Sequential\nfrom keras import regularizers\nfrom keras.layers import BatchNormalization\n\npretrained_model = Xception(\n    include_top=False,\n    weights=\"imagenet\",\n    input_shape=(target_size[0], target_size[1], 3),\n    pooling=\"max\"\n)\n\npretrained_model.trainable = False\n\nfrom keras.callbacks import ModelCheckpoint\n\ncheckpoint_path = \"checkpoints\"\ncheckpoint_cb = ModelCheckpoint(\n    filepath=checkpoint_path,\n    save_best_only=True,\n    save_weights_only=True,\n    monitor=\"val_accuracy\",\n)\n\nfrom keras.callbacks import EarlyStopping\n\nearly_stopping_cb = EarlyStopping(\n    monitor = \"val_loss\", # watch the val loss metric\n    patience = 5,\n    restore_best_weights = True\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:17:58.558111Z","iopub.execute_input":"2024-03-03T17:17:58.558426Z","iopub.status.idle":"2024-03-03T17:18:00.966117Z","shell.execute_reply.started":"2024-03-03T17:17:58.558399Z","shell.execute_reply":"2024-03-03T17:18:00.965277Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Dense, Dropout, GlobalAveragePooling2D, Flatten, GaussianNoise, Conv2D, BatchNormalization, MaxPooling2D\nfrom keras.models import Model\nfrom keras.optimizers import Adam\n\ndef build_model():\n\n    num_classes = train_images.num_classes\n\n    # Load the pre-trained Xception model\n    base_model = Xception(weights='imagenet', include_top=False, input_shape=(target_size[0], target_size[1], 3))\n\n    # Freeze the layers in the base model\n    base_model.trainable = False\n\n    # Create a new model with improvements\n    model = Sequential([\n        base_model,\n        Conv2D(256, (3, 3), activation='relu', padding='same'),\n        MaxPooling2D((2, 2)),\n        BatchNormalization(),\n        Conv2D(512, (3, 3), activation='relu', padding='same'),\n        MaxPooling2D((2, 2)),\n        BatchNormalization(),\n        GlobalAveragePooling2D(),\n        GaussianNoise(0.3),\n        Dense(512, activation='relu'),\n        Dropout(0.5),\n        BatchNormalization(),\n        Dense(256, activation='relu'),\n        Dropout(0.5),\n        BatchNormalization(),\n        Dense(num_classes, activation='softmax')\n    ])\n\n    # Compile the model\n    model.compile(optimizer=Adam(learning_rate=0.001),\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:18:00.967346Z","iopub.execute_input":"2024-03-03T17:18:00.967719Z","iopub.status.idle":"2024-03-03T17:18:00.978396Z","shell.execute_reply.started":"2024-03-03T17:18:00.967686Z","shell.execute_reply":"2024-03-03T17:18:00.977478Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# with strategy.scope():\n#     multi_gpu_model = build_model()\nmulti_gpu_model = build_model()\nmulti_gpu_model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:18:00.979694Z","iopub.execute_input":"2024-03-03T17:18:00.980233Z","iopub.status.idle":"2024-03-03T17:18:03.124715Z","shell.execute_reply.started":"2024-03-03T17:18:00.980207Z","shell.execute_reply":"2024-03-03T17:18:03.120753Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n xception (Functional)       (None, 5, 5, 2048)        20861480  \n                                                                 \n conv2d_8 (Conv2D)           (None, 5, 5, 256)         4718848   \n                                                                 \n max_pooling2d (MaxPooling2  (None, 2, 2, 256)         0         \n D)                                                              \n                                                                 \n batch_normalization_8 (Bat  (None, 2, 2, 256)         1024      \n chNormalization)                                                \n                                                                 \n conv2d_9 (Conv2D)           (None, 2, 2, 512)         1180160   \n                                                                 \n max_pooling2d_1 (MaxPoolin  (None, 1, 1, 512)         0         \n g2D)                                                            \n                                                                 \n batch_normalization_9 (Bat  (None, 1, 1, 512)         2048      \n chNormalization)                                                \n                                                                 \n global_average_pooling2d (  (None, 512)               0         \n GlobalAveragePooling2D)                                         \n                                                                 \n gaussian_noise (GaussianNo  (None, 512)               0         \n ise)                                                            \n                                                                 \n dense (Dense)               (None, 512)               262656    \n                                                                 \n dropout (Dropout)           (None, 512)               0         \n                                                                 \n batch_normalization_10 (Ba  (None, 512)               2048      \n tchNormalization)                                               \n                                                                 \n dense_1 (Dense)             (None, 256)               131328    \n                                                                 \n dropout_1 (Dropout)         (None, 256)               0         \n                                                                 \n batch_normalization_11 (Ba  (None, 256)               1024      \n tchNormalization)                                               \n                                                                 \n dense_2 (Dense)             (None, 21)                5397      \n                                                                 \n=================================================================\nTotal params: 27166013 (103.63 MB)\nTrainable params: 6301461 (24.04 MB)\nNon-trainable params: 20864552 (79.59 MB)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# from keras.preprocessing import image\n# from keras.applications.xception import preprocess_input\n# import numpy as np\n\n# # Assuming you have already created the test_generator as mentioned in your code\n\n# # Get one batch of images from the generator\n# batch = next(test_images)\n\n# # Retrieve the first image from the batch\n# image_array = batch[0]\n\n# # Convert the image array to a PIL Image or matplotlib plot (optional)\n# img = image.array_to_img(image_array)\n\n# # Convert the PIL Image to a format suitable for your model\n# img_array = image.img_to_array(img)\n# img_array = np.expand_dims(img_array, axis=0)\n# img_array = preprocess_input(img_array)\n\n# # Now, you can use img_array for prediction\n# warmup_results = multi_gpu_model.predict(img_array)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:18:03.128448Z","iopub.execute_input":"2024-03-03T17:18:03.128746Z","iopub.status.idle":"2024-03-03T17:18:04.128298Z","shell.execute_reply.started":"2024-03-03T17:18:03.128720Z","shell.execute_reply":"2024-03-03T17:18:04.126713Z"},"trusted":true},"execution_count":9,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m image_array \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Convert the image array to a PIL Image or matplotlib plot (optional)\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_to_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Convert the PIL Image to a format suitable for your model\u001b[39;00m\n\u001b[1;32m     17\u001b[0m img_array \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mimg_to_array(img)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/image_utils.py:247\u001b[0m, in \u001b[0;36marray_to_img\u001b[0;34m(x, data_format, scale, dtype)\u001b[0m\n\u001b[1;32m    245\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    248\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected image array to have rank 3 (single image). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    249\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot array with shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m     )\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_format \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannels_first\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannels_last\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid data_format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mValueError\u001b[0m: Expected image array to have rank 3 (single image). Got array with shape: (32, 142, 142, 3)"],"ename":"ValueError","evalue":"Expected image array to have rank 3 (single image). Got array with shape: (32, 142, 142, 3)","output_type":"error"}]},{"cell_type":"code","source":"history = multi_gpu_model.fit(\n    train_images,\n    steps_per_epoch=len(train_images),\n    validation_data=val_images,\n    validation_steps=len(val_images),\n    epochs=50,\n    callbacks=[\n        early_stopping_cb,\n        checkpoint_cb,\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:19:01.203015Z","iopub.execute_input":"2024-03-03T17:19:01.203441Z","iopub.status.idle":"2024-03-03T17:57:20.565853Z","shell.execute_reply.started":"2024-03-03T17:19:01.203408Z","shell.execute_reply":"2024-03-03T17:57:20.564972Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1709486350.146073    5315 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"460/460 [==============================] - 129s 258ms/step - loss: 1.8789 - accuracy: 0.4384 - val_loss: 1.1136 - val_accuracy: 0.6489\nEpoch 2/50\n460/460 [==============================] - 99s 214ms/step - loss: 1.3651 - accuracy: 0.5824 - val_loss: 1.0754 - val_accuracy: 0.6673\nEpoch 3/50\n460/460 [==============================] - 99s 216ms/step - loss: 1.2092 - accuracy: 0.6235 - val_loss: 1.0234 - val_accuracy: 0.6813\nEpoch 4/50\n460/460 [==============================] - 101s 220ms/step - loss: 1.1573 - accuracy: 0.6443 - val_loss: 0.9649 - val_accuracy: 0.6863\nEpoch 5/50\n460/460 [==============================] - 100s 217ms/step - loss: 1.0906 - accuracy: 0.6667 - val_loss: 0.9101 - val_accuracy: 0.6990\nEpoch 6/50\n460/460 [==============================] - 99s 216ms/step - loss: 1.0460 - accuracy: 0.6782 - val_loss: 0.9063 - val_accuracy: 0.7140\nEpoch 7/50\n460/460 [==============================] - 98s 213ms/step - loss: 1.0306 - accuracy: 0.6846 - val_loss: 0.9092 - val_accuracy: 0.7098\nEpoch 8/50\n460/460 [==============================] - 100s 218ms/step - loss: 1.0052 - accuracy: 0.6873 - val_loss: 0.9031 - val_accuracy: 0.7162\nEpoch 9/50\n460/460 [==============================] - 115s 250ms/step - loss: 0.9786 - accuracy: 0.6994 - val_loss: 0.8552 - val_accuracy: 0.7273\nEpoch 10/50\n460/460 [==============================] - 104s 225ms/step - loss: 0.9453 - accuracy: 0.7087 - val_loss: 0.8711 - val_accuracy: 0.7251\nEpoch 11/50\n460/460 [==============================] - 99s 216ms/step - loss: 0.9183 - accuracy: 0.7141 - val_loss: 0.8346 - val_accuracy: 0.7317\nEpoch 12/50\n460/460 [==============================] - 100s 217ms/step - loss: 0.9071 - accuracy: 0.7183 - val_loss: 0.8279 - val_accuracy: 0.7394\nEpoch 13/50\n460/460 [==============================] - 104s 227ms/step - loss: 0.8966 - accuracy: 0.7208 - val_loss: 0.8118 - val_accuracy: 0.7422\nEpoch 14/50\n460/460 [==============================] - 108s 234ms/step - loss: 0.8665 - accuracy: 0.7278 - val_loss: 0.8441 - val_accuracy: 0.7311\nEpoch 15/50\n460/460 [==============================] - 108s 234ms/step - loss: 0.8626 - accuracy: 0.7309 - val_loss: 0.8117 - val_accuracy: 0.7422\nEpoch 16/50\n460/460 [==============================] - 105s 229ms/step - loss: 0.8270 - accuracy: 0.7403 - val_loss: 0.8354 - val_accuracy: 0.7413\nEpoch 17/50\n460/460 [==============================] - 113s 245ms/step - loss: 0.8357 - accuracy: 0.7376 - val_loss: 0.7875 - val_accuracy: 0.7517\nEpoch 18/50\n460/460 [==============================] - 108s 235ms/step - loss: 0.8155 - accuracy: 0.7445 - val_loss: 0.8080 - val_accuracy: 0.7438\nEpoch 19/50\n460/460 [==============================] - 102s 221ms/step - loss: 0.8038 - accuracy: 0.7501 - val_loss: 0.8043 - val_accuracy: 0.7486\nEpoch 20/50\n460/460 [==============================] - 103s 224ms/step - loss: 0.7883 - accuracy: 0.7488 - val_loss: 0.7976 - val_accuracy: 0.7502\nEpoch 21/50\n460/460 [==============================] - 101s 218ms/step - loss: 0.7775 - accuracy: 0.7554 - val_loss: 0.8202 - val_accuracy: 0.7498\nEpoch 22/50\n460/460 [==============================] - 104s 226ms/step - loss: 0.7643 - accuracy: 0.7575 - val_loss: 0.7902 - val_accuracy: 0.7530\n","output_type":"stream"}]},{"cell_type":"code","source":"multi_gpu_model.save(f'/kaggle/working/model.keras')","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:18:04.130894Z","iopub.status.idle":"2024-03-03T17:18:04.131297Z","shell.execute_reply.started":"2024-03-03T17:18:04.131112Z","shell.execute_reply":"2024-03-03T17:18:04.131127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = multi_gpu_model.evaluate(test_images)\n\nprint(\"    Test Loss: {:.5f}\".format(results[0]))\nprint(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:18:04.132425Z","iopub.status.idle":"2024-03-03T17:18:04.132884Z","shell.execute_reply.started":"2024-03-03T17:18:04.132658Z","shell.execute_reply":"2024-03-03T17:18:04.132678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\naccuracy = history.history['accuracy']\nval_accuracy = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(accuracy))\nplt.plot(epochs, accuracy, 'b', label='Training accuracy')\nplt.plot(epochs, val_accuracy, 'r', label='Validation accuracy')\n\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\n\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:18:04.133829Z","iopub.status.idle":"2024-03-03T17:18:04.134328Z","shell.execute_reply.started":"2024-03-03T17:18:04.134049Z","shell.execute_reply":"2024-03-03T17:18:04.134071Z"},"trusted":true},"execution_count":null,"outputs":[]}]}